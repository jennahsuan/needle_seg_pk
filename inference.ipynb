{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @model\n",
    "import json, os, random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import Mask2Former\n",
    "from lib.config_helper import merge\n",
    "\n",
    "\n",
    "ckpt_path = \"./transnext_mask2former_checkpoints/transnext_mask2former_cls_T512_pix_add1_ema.pth\"\n",
    "\n",
    "with open(\"config.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)\n",
    "if config[\"Model\"].get(\"structure\") == \"mask2former\":\n",
    "    with open(\"./model/mask2former/m2f_config.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        m2f_config = json.load(f)\n",
    "    config = merge(config, m2f_config)\n",
    "    \n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_name = torch.cuda.get_device_name(device) if torch.cuda.is_available() else \"CPU\"\n",
    "print(f\"Device: {device_name}\")\n",
    "\n",
    "if \"mask2former_decoder\" in config[\"Model\"]:\n",
    "    if config[\"Model\"][\"unet_backbone\"][\"encoder_type\"] == \"TransNeXt-Tiny\":\n",
    "        model_name = \"TransNeXt-Mask2Former\"\n",
    "    elif config[\"Model\"][\"unet_backbone\"][\"encoder_type\"] == \"Swin-Small\":\n",
    "        model_name = \"SwinUNet-Mask2Former\"\n",
    "    elif config[\"Model\"][\"unet_backbone\"][\"encoder_type\"] == \"Swin-SMT\":\n",
    "        model_name = \"SwinSMT-Mask2Former\"\n",
    "    print(model_name)\n",
    "else:\n",
    "    raise NotImplementedError \n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Model Configuration & Initialization\n",
    "# --------------------------------------------------------------------------\n",
    "# Create the model\n",
    "# merge config for mask2former\n",
    "with open(\"./model/mask2former/m2f_config.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    m2f_config = json.load(f)\n",
    "config = merge(config, m2f_config)\n",
    "model = Mask2Former(config)\n",
    "# model.load_pretrained_weight()\n",
    "anchors_pos = None\n",
    "det_head = False\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Read ckpt\n",
    "# --------------------------------------------------------------------------\n",
    "ckpt = torch.load(ckpt_path)\n",
    "if \"n_averaged\" in ckpt.keys(): ## key names in ema_model & model are slightly different\n",
    "    ema_model = torch.optim.swa_utils.AveragedModel(model, multi_avg_fn=torch.optim.swa_utils.get_ema_multi_avg_fn(config[\"Validation\"][\"ema\"]))\n",
    "    model = ema_model\n",
    "model.load_state_dict(ckpt, strict=True)\n",
    "print(f\"Ckpt loaded {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## folders for inference\n",
    "folder_name_list = [\n",
    "\"Sonosite20241008_1401_474frams_abc(待茹瑄_似蓉_承原)\",\n",
    "'Sonosite20241008_1207_158frams_abc(待茹瑄_似蓉_承原)',\n",
    "'Sonosite20241008_1301_360frams_abc(待茹瑄_似蓉_承原)',\n",
    "'Sonosite20241008_1334_212frams_abc(待茹瑄_似蓉_承原)',\n",
    "'Sonosite20241008_1146_1066frams_abc(待茹瑄_似蓉_承原)',\n",
    "'Sonosite20240924_1205_378frams_abc(待茹瑄_似蓉_承原)',\n",
    "'Sonosite20241008_1148_1070frams_abc(待茹瑄_似蓉_承原)',\n",
    "'Sonosite20241008_1144_1056frams_abc(待茹瑄_似蓉_承原)',\n",
    "'Sonosite20241008_0946_910frams_abc(待茹瑄_似蓉_承原)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from dataset import UnlabeledDataset, Augmentation\n",
    "from evaluation_v2 import inference\n",
    "\n",
    "valid_transform = Augmentation(crop=False, rotate=False, color_jitter=False, horizontal_flip=False, image_size=512)\n",
    "\n",
    "for folder_name in folder_name_list:\n",
    "\n",
    "    medium_test_dataset = UnlabeledDataset(f\"C:/Dropbox/家庭資料室/{folder_name}\", transform=valid_transform,\n",
    "                                        time_window=3,\n",
    "                                        buffer_num_sample=1,\n",
    "                                        line_width=20,\n",
    "                                        det_num_classes=1,\n",
    "                                    )\n",
    "    ## Test batch size 1\n",
    "    loader = DataLoader(medium_test_dataset, batch_size=1, shuffle=False, drop_last=False, num_workers=4, persistent_workers=True, pin_memory=True)\n",
    "    print(len(medium_test_dataset))\n",
    "\n",
    "    sample = next(iter(loader))\n",
    "    print(sample[\"images\"].shape)\n",
    "    print(sample[\"img_path\"][2])\n",
    "\n",
    "    ## similar to evaluate function but writes points to json file\n",
    "    inference(model, device, loader, det_head, save_json=True)\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "needle_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
