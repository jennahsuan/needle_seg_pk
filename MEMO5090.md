## Memo
Unsure why cuda fails when setting directly at local, so repo is clone to **WSL**

### Environment
- Current environment Settings:
	- WSL Settings 
		- distribution: Ubuntu
		- version: 2
		- **password: 963963**
	- GPU related Settings
		- cuda 12.8 (12.9 might be unstable)
		- pytorch 2.8.0
	- Conda Settings
		- python 3.12

- Access in command line or powershell
	```bash
	wsl  ## enter 
	## By default, the root directory is home/username(sonav), clone this repo.
	cd /home/sonav/needle_seg_pk
	source activate base ## optional
	conda activate needle_seg
	exit ## leave
	```

- If you need to set a new environment (WSL & CUDA & Conda)
	1. Follow [official user guide](https://docs.nvidia.com/cuda/wsl-user-guide/index.html) and https://blog.csdn.net/LoongEmbedded/article/details/127842365 to install WSL, CUDA Toolkit, and Anaconda. CUDA Toolkit Download: `Linux` `WSL-Ubuntu` `2.0` `x86_64`, installer type: `deb(local)`
	2. Install torch (see [instruction from nvidia engineer](https://github.com/lllyasviel/Fooocus/issues/3862#issuecomment-2637819598))
		```bash
		pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128
		```
	3. Make sure the needed files in Dropbox are accessible at local
	4. Clone git repo under `/home/sonav` (program under `/home/` seemed faster than in `/mnt/c/Users`)
	5. Build conda environment
		```bash
		cd needle_seg_pk
		conda env create -f environment_linux.yml
		```
<!-- 6. Speedup extension in TransNeXt (Optional)

		Follow https://github.com/DaiShiResearch/TransNeXt?tab=readme-ov-file#cuda-implementation,
		download and move swattention_extension folder to `./model/mask2former`
			```bash
			cd ./model/mask2former/swattention_extension
			pip install .
			```
		NOTE: This should be done under `conda activate needle_seg` 
		If "error: Microsoft Visual C++ 14.0 or greater is required", download Microsoft C++ Build Tools. -->

<!-- NOTE: temporally close all swattention due to error in installing swattention 
build memm2f and inference slow -->

## Model Developer MEMO
### Model Settings (End User no need to look into this)
* Segmentation model
	<!-- * `transnext_mask2former_cls_T512384_pixup_foc20aux1_v6imgLCR_k2`:
		- `config.json`
			- "image_size" : 384
			- "structure" : "mask2former"
		- `m2f_config.json`
			- "encoder_type" : "TransNeXt-Tiny"
			- "decoder_type": "pixelup" -->
	
	* `convnext_mask2former_cls_rB384_pixup_foc20aux1_v6imgLCR_k2`:
		- `configs/config.json`
			- "image_size" : 384
			- "structure" : "mask2former"
		- `model/mask2former/m2f_config.json`
			- "encoder_type" : "ConvNext"
			- "decoder_type": "pixelup"

* Track model
	* `memm2f_cls_rB384_pixu_RNA_C2sam2_BLLF20MA2_tciou78_2BqattGP_v6imgLCR_k2_update`:
		- `configs/config.json`
			- "image_size" : 384
			- "structure" : "mem_m2f"
		- `model/memmask2former/mem_m2f_config.json`
			- "encoder_type" : "ConvNext"
			- "decoder_type": "pixel"
			- "vis_query_att":true
			- "branch":2
			- "short_term_t":1
			- "qatt_block":"gp"
